{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./kaggle.json') as f:\n",
    "    kaggle_credentials = json.load(f)\n",
    "\n",
    "    os.environ['KAGGLE_USERNAME'] = kaggle_credentials['username']\n",
    "    os.environ['KAGGLE_KEY'] = kaggle_credentials['key']\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(\"hitman1309/isic-2018-task-3\", unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r'img_path'  # Update with your image directory\n",
    "mask_dir = r'mask_path'    # Update with your mask directory\n",
    "\n",
    "image_size = (128, 128)  # Resize to a smaller size if necessary\n",
    "batch_size = 32\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "def load_data(image_dir, mask_dir, image_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    image_filenames = sorted(os.listdir(image_dir))\n",
    "    mask_filenames = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for image_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        image = load_img(os.path.join(image_dir, image_file), target_size=image_size)\n",
    "        mask = load_img(os.path.join(mask_dir, mask_file), target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "        image = img_to_array(image) / 255.0\n",
    "        mask = img_to_array(mask) / 255.0\n",
    "\n",
    "        images.append(image)\n",
    "        masks.append(mask)\n",
    "\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "images, masks = load_data(image_dir, mask_dir, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(128, 128, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = unet_model(input_size=(128, 128, 3))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=50,  # Adjust according to your dataset\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {loss}, Validation Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "def visualize_predictions(images, masks, model):\n",
    "    predictions = model.predict(images)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(\"Image\")\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(masks[i].squeeze(), cmap='gray')\n",
    "        plt.title(\"Mask\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "        plt.title(\"Prediction\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "visualize_predictions(X_val[:5], y_val[:5], model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
